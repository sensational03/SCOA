{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ymPn7N-f74O",
        "outputId": "5fcf80a7-fff8-43d7-8a7b-51af8f53ebfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 0 - Best Fitness: 0.9667\n",
            "Generation 1 - Best Fitness: 0.9667\n",
            "Generation 2 - Best Fitness: 0.9667\n",
            "Generation 3 - Best Fitness: 0.9667\n",
            "Generation 4 - Best Fitness: 0.9667\n",
            "Generation 5 - Best Fitness: 0.9667\n",
            "Generation 6 - Best Fitness: 0.9667\n",
            "Generation 7 - Best Fitness: 0.9667\n",
            "Generation 8 - Best Fitness: 0.9667\n",
            "Generation 9 - Best Fitness: 0.9667\n",
            "\n",
            "Best Hyperparameters: [8, 9]\n",
            "Best Accuracy: 0.9666666666666668\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# --- Genetic Algorithm Setup ---\n",
        "POP_SIZE = 20      # number of individuals\n",
        "N_GENERATIONS = 10 # iterations\n",
        "MUTATION_RATE = 0.2\n",
        "\n",
        "# Chromosome: [max_depth, min_samples_split]\n",
        "def create_chromosome():\n",
        "    return [random.randint(1, 20), random.randint(2, 10)]\n",
        "\n",
        "def fitness(chromosome):\n",
        "    max_depth, min_samples_split = chromosome\n",
        "    model = DecisionTreeClassifier(max_depth=max_depth,\n",
        "                                   min_samples_split=min_samples_split)\n",
        "    scores = cross_val_score(model, X, y, cv=5)\n",
        "    return scores.mean()\n",
        "\n",
        "def selection(population, fitnesses):\n",
        "    idx = np.argsort(fitnesses)[-2:]  # select best two\n",
        "    return [population[idx[0]], population[idx[1]]]\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    point = random.randint(0, len(parent1)-1)\n",
        "    child1 = parent1[:point] + parent2[point:]\n",
        "    child2 = parent2[:point] + parent1[point:]\n",
        "    return child1, child2\n",
        "\n",
        "def mutate(chromosome):\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        chromosome[0] = random.randint(1, 20)\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        chromosome[1] = random.randint(2, 10)\n",
        "    return chromosome\n",
        "\n",
        "# --- Run GA ---\n",
        "population = [create_chromosome() for _ in range(POP_SIZE)]\n",
        "\n",
        "for gen in range(N_GENERATIONS):\n",
        "    fitnesses = [fitness(chromo) for chromo in population]\n",
        "    print(f\"Generation {gen} - Best Fitness: {max(fitnesses):.4f}\")\n",
        "\n",
        "    new_population = []\n",
        "    parents = selection(population, fitnesses)\n",
        "    for _ in range(POP_SIZE // 2):\n",
        "        child1, child2 = crossover(parents[0], parents[1])\n",
        "        new_population.append(mutate(child1))\n",
        "        new_population.append(mutate(child2))\n",
        "\n",
        "    population = new_population\n",
        "\n",
        "# Best result\n",
        "fitnesses = [fitness(chromo) for chromo in population]\n",
        "best_idx = np.argmax(fitnesses)\n",
        "print(\"\\nBest Hyperparameters:\", population[best_idx])\n",
        "print(\"Best Accuracy:\", fitnesses[best_idx])\n",
        "\n",
        "# ============================================================================\n",
        "# GENETIC ALGORITHM FOR MACHINE LEARNING HYPERPARAMETER OPTIMIZATION\n",
        "# ============================================================================\n",
        "#\n",
        "# GOAL: Find the best hyperparameters for a Decision Tree to maximize accuracy\n",
        "#\n",
        "# APPROACH: Use Genetic Algorithm (inspired by natural evolution)\n",
        "# - Population: 20 candidate solutions (sets of hyperparameters)\n",
        "# - Evolution: 10 generations of selection, crossover, and mutation\n",
        "# - Fitness: Cross-validation accuracy (higher = better)\n",
        "#\n",
        "# KEY CONCEPT - GENETIC ALGORITHM:\n",
        "# 1. Start with random solutions (population)\n",
        "# 2. Evaluate each solution (fitness)\n",
        "# 3. Select best solutions (parents)\n",
        "# 4. Combine parents to create offspring (crossover)\n",
        "# 5. Randomly modify offspring (mutation)\n",
        "# 6. Repeat for multiple generations\n",
        "# 7. Best solution emerges through evolution\n",
        "#\n",
        "# ANALOGY: Like breeding animals - keep best traits, combine them,\n",
        "#          occasionally introduce random changes\n",
        "#\n",
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "#\n",
        "# import numpy as np\n",
        "# - For numerical operations and array handling\n",
        "#\n",
        "# import random\n",
        "# - For random number generation in GA operations\n",
        "#\n",
        "# from sklearn.datasets import load_iris\n",
        "# - Load famous Iris flower dataset (150 samples, 3 classes)\n",
        "#\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# - Evaluate model using k-fold cross-validation (prevents overfitting)\n",
        "#\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# - Machine learning model we're optimizing\n",
        "#\n",
        "# ============================================================================\n",
        "# LOAD DATASET\n",
        "# ============================================================================\n",
        "#\n",
        "# iris = load_iris()\n",
        "# - Loads Iris dataset containing:\n",
        "#   * 150 samples (flowers)\n",
        "#   * 4 features (sepal length, sepal width, petal length, petal width)\n",
        "#   * 3 classes (Setosa, Versicolor, Virginica)\n",
        "#\n",
        "# X, y = iris.data, iris.target\n",
        "# - X: Feature matrix (150 samples × 4 features)\n",
        "# - y: Target labels (150 labels: 0, 1, or 2)\n",
        "#\n",
        "# ============================================================================\n",
        "# GA PARAMETERS\n",
        "# ============================================================================\n",
        "#\n",
        "# POP_SIZE = 20\n",
        "# - Number of candidate solutions in each generation\n",
        "# - More = better exploration but slower\n",
        "#\n",
        "# N_GENERATIONS = 10\n",
        "# - Number of evolution cycles\n",
        "# - More = better convergence but slower\n",
        "#\n",
        "# MUTATION_RATE = 0.2\n",
        "# - Probability of random change (20% chance)\n",
        "# - Prevents getting stuck in local optima\n",
        "#\n",
        "# ============================================================================\n",
        "# CHROMOSOME REPRESENTATION\n",
        "# ============================================================================\n",
        "#\n",
        "# Each chromosome encodes 2 hyperparameters as a list:\n",
        "# [max_depth, min_samples_split]\n",
        "#\n",
        "# max_depth (1-20):\n",
        "# - Maximum depth of decision tree\n",
        "# - Deeper = more complex, may overfit\n",
        "# - Shallower = simpler, may underfit\n",
        "#\n",
        "# min_samples_split (2-10):\n",
        "# - Minimum samples required to split a node\n",
        "# - Higher = simpler tree (fewer splits)\n",
        "# - Lower = more complex tree (more splits)\n",
        "#\n",
        "# EXAMPLE: [8, 5] means max_depth=8, min_samples_split=5\n",
        "#\n",
        "# ============================================================================\n",
        "# CREATE CHROMOSOME\n",
        "# ============================================================================\n",
        "#\n",
        "# def create_chromosome():\n",
        "#     return [random.randint(1, 20), random.randint(2, 10)]\n",
        "#\n",
        "# - Generates random hyperparameter values\n",
        "# - max_depth: random integer between 1 and 20\n",
        "# - min_samples_split: random integer between 2 and 10\n",
        "# - Returns list with 2 values\n",
        "#\n",
        "# EXAMPLE OUTPUT: [12, 7] or [3, 9] or [18, 4]\n",
        "#\n",
        "# ============================================================================\n",
        "# FITNESS FUNCTION\n",
        "# ============================================================================\n",
        "#\n",
        "# def fitness(chromosome):\n",
        "#     max_depth, min_samples_split = chromosome\n",
        "#\n",
        "# - Unpacks chromosome into individual hyperparameters\n",
        "# - Example: [8, 5] → max_depth=8, min_samples_split=5\n",
        "#\n",
        "#     model = DecisionTreeClassifier(max_depth=max_depth,\n",
        "#                                    min_samples_split=min_samples_split)\n",
        "#\n",
        "# - Creates Decision Tree with specified hyperparameters\n",
        "# - These parameters control tree complexity and generalization\n",
        "#\n",
        "#     scores = cross_val_score(model, X, y, cv=5)\n",
        "#\n",
        "# - Evaluates model using 5-fold cross-validation\n",
        "# - Splits data into 5 parts, trains on 4, tests on 1, repeats 5 times\n",
        "# - Returns array of 5 accuracy scores\n",
        "# - Example: [0.93, 0.97, 0.90, 0.93, 0.97]\n",
        "#\n",
        "# WHY CROSS-VALIDATION?\n",
        "# - Prevents overfitting (testing on unseen data)\n",
        "# - More reliable than single train-test split\n",
        "# - Uses all data for both training and testing\n",
        "#\n",
        "#     return scores.mean()\n",
        "#\n",
        "# - Returns average accuracy across 5 folds\n",
        "# - Example: (0.93 + 0.97 + 0.90 + 0.93 + 0.97) / 5 = 0.94\n",
        "# - This is the fitness value (higher = better)\n",
        "#\n",
        "# ============================================================================\n",
        "# SELECTION\n",
        "# ============================================================================\n",
        "#\n",
        "# def selection(population, fitnesses):\n",
        "#     idx = np.argsort(fitnesses)[-2:]\n",
        "#\n",
        "# - np.argsort(fitnesses): Returns indices that would sort array\n",
        "#   Example: fitnesses = [0.85, 0.92, 0.78, 0.95, 0.88]\n",
        "#            argsort gives: [2, 0, 4, 1, 3] (sorted order)\n",
        "#\n",
        "# - [-2:]: Takes last 2 indices (highest fitness)\n",
        "#   Example: [1, 3] (individuals at positions 1 and 3 are best)\n",
        "#\n",
        "#     return [population[idx[0]], population[idx[1]]]\n",
        "#\n",
        "# - Returns the 2 best chromosomes as parents\n",
        "# - These will be used to create offspring\n",
        "#\n",
        "# SELECTION STRATEGY: Elitism (always keep best)\n",
        "# - Ensures good solutions aren't lost\n",
        "# - Simple and effective\n",
        "#\n",
        "# ============================================================================\n",
        "# CROSSOVER\n",
        "# ============================================================================\n",
        "#\n",
        "# def crossover(parent1, parent2):\n",
        "#     point = random.randint(0, len(parent1)-1)\n",
        "#\n",
        "# - Chooses random crossover point (0 or 1)\n",
        "# - Determines where to split chromosomes\n",
        "# - Example: point = 1\n",
        "#\n",
        "#     child1 = parent1[:point] + parent2[point:]\n",
        "#     child2 = parent2[:point] + parent1[point:]\n",
        "#\n",
        "# - Combines parts of both parents\n",
        "#\n",
        "# EXAMPLE:\n",
        "# parent1 = [15, 3]  parent2 = [8, 7]  point = 1\n",
        "# child1 = [15] + [7] = [15, 7]  (max_depth from p1, split from p2)\n",
        "# child2 = [8] + [3] = [8, 3]    (max_depth from p2, split from p1)\n",
        "#\n",
        "# PURPOSE: Combine good traits from both parents\n",
        "#\n",
        "#     return child1, child2\n",
        "#\n",
        "# ============================================================================\n",
        "# MUTATION\n",
        "# ============================================================================\n",
        "#\n",
        "# def mutate(chromosome):\n",
        "#     if random.random() < MUTATION_RATE:\n",
        "#         chromosome[0] = random.randint(1, 20)\n",
        "#\n",
        "# - 20% chance to randomly change max_depth\n",
        "# - Introduces new genetic material\n",
        "# - Helps explore new solutions\n",
        "#\n",
        "#     if random.random() < MUTATION_RATE:\n",
        "#         chromosome[1] = random.randint(2, 10)\n",
        "#\n",
        "# - 20% chance to randomly change min_samples_split\n",
        "# - Independent from first mutation\n",
        "#\n",
        "#     return chromosome\n",
        "#\n",
        "# EXAMPLE:\n",
        "# Input: [15, 7]\n",
        "# If both mutations happen: [12, 4]\n",
        "# If only first: [18, 7]\n",
        "# If neither: [15, 7]\n",
        "#\n",
        "# PURPOSE: Prevent premature convergence, explore new regions\n",
        "#\n",
        "# ============================================================================\n",
        "# INITIALIZE POPULATION\n",
        "# ============================================================================\n",
        "#\n",
        "# population = [create_chromosome() for _ in range(POP_SIZE)]\n",
        "#\n",
        "# - Creates 20 random chromosomes\n",
        "# - List comprehension calls create_chromosome() 20 times\n",
        "#\n",
        "# EXAMPLE:\n",
        "# [[15, 3], [8, 7], [12, 5], [3, 9], ..., [18, 4]]\n",
        "# 20 different random hyperparameter combinations\n",
        "#\n",
        "# ============================================================================\n",
        "# MAIN GA LOOP\n",
        "# ============================================================================\n",
        "#\n",
        "# for gen in range(N_GENERATIONS):\n",
        "# - Runs for 10 generations (evolution cycles)\n",
        "#\n",
        "#     fitnesses = [fitness(chromo) for chromo in population]\n",
        "#\n",
        "# - Evaluates all 20 chromosomes\n",
        "# - Each fitness call trains and tests a Decision Tree\n",
        "# - Returns list of 20 accuracy values\n",
        "# - Example: [0.85, 0.92, 0.78, 0.95, ..., 0.88]\n",
        "#\n",
        "#     print(f\"Generation {gen} - Best Fitness: {max(fitnesses):.4f}\")\n",
        "#\n",
        "# - Displays best accuracy in current generation\n",
        "# - Shows optimization progress\n",
        "# - Example: \"Generation 0 - Best Fitness: 0.9533\"\n",
        "#\n",
        "#     new_population = []\n",
        "# - Empty list to store offspring\n",
        "#\n",
        "#     parents = selection(population, fitnesses)\n",
        "#\n",
        "# - Selects 2 best chromosomes from current population\n",
        "# - These will be parents for all offspring\n",
        "# - Example: [[15, 3], [8, 7]]\n",
        "#\n",
        "#     for _ in range(POP_SIZE // 2):\n",
        "#\n",
        "# - Loop 10 times (20 // 2 = 10)\n",
        "# - Each iteration creates 2 children (total 20)\n",
        "#\n",
        "#         child1, child2 = crossover(parents[0], parents[1])\n",
        "#\n",
        "# - Combines parents to create 2 offspring\n",
        "# - Offspring inherit traits from both parents\n",
        "#\n",
        "#         new_population.append(mutate(child1))\n",
        "#         new_population.append(mutate(child2))\n",
        "#\n",
        "# - Applies mutation to each child\n",
        "# - Adds both to new population\n",
        "# - After 10 loops: 20 new individuals\n",
        "#\n",
        "#     population = new_population\n",
        "#\n",
        "# - Replaces old generation with new generation\n",
        "# - Evolution continues with improved population\n",
        "#\n",
        "# ============================================================================\n",
        "# FINAL RESULT\n",
        "# ============================================================================\n",
        "#\n",
        "# fitnesses = [fitness(chromo) for chromo in population]\n",
        "# - Evaluates final generation\n",
        "#\n",
        "# best_idx = np.argmax(fitnesses)\n",
        "# - Finds index of best chromosome\n",
        "# - argmax returns position of maximum value\n",
        "#\n",
        "# print(\"\\nBest Hyperparameters:\", population[best_idx])\n",
        "# - Displays optimal hyperparameters found\n",
        "# - Example: [8, 5]\n",
        "#\n",
        "# print(\"Best Accuracy:\", fitnesses[best_idx])\n",
        "# - Displays best accuracy achieved\n",
        "# - Example: 0.9667\n",
        "#\n",
        "# ============================================================================\n",
        "# COMPLETE EXAMPLE RUN\n",
        "# ============================================================================\n",
        "#\n",
        "# Generation 0: Random population, best = 0.9267\n",
        "# Generation 1: After evolution, best = 0.9467\n",
        "# Generation 2: Improving, best = 0.9533\n",
        "# Generation 5: Converging, best = 0.9600\n",
        "# Generation 9: Final, best = 0.9667\n",
        "#\n",
        "# Best Hyperparameters: [8, 5]\n",
        "# Best Accuracy: 0.9667\n",
        "#\n",
        "# INTERPRETATION:\n",
        "# - max_depth=8: Moderately deep tree\n",
        "# - min_samples_split=5: Moderate splitting threshold\n",
        "# - Accuracy=96.67%: Very good performance\n",
        "#\n",
        "# ============================================================================\n",
        "# WHY GA WORKS\n",
        "# ============================================================================\n",
        "#\n",
        "# 1. EXPLORATION: Random initial population covers search space\n",
        "# 2. EXPLOITATION: Selection keeps best solutions\n",
        "# 3. RECOMBINATION: Crossover combines good traits\n",
        "# 4. INNOVATION: Mutation introduces new possibilities\n",
        "# 5. ITERATION: Process repeats, gradually improving\n",
        "#\n",
        "# ADVANTAGE OVER MANUAL TUNING:\n",
        "# - Automatic (no human trial-and-error)\n",
        "# - Explores many combinations efficiently\n",
        "# - Finds near-optimal solutions\n",
        "# - Better than random search or grid search\n",
        "#\n",
        "# ============================================================================\n",
        "# KEY TAKEAWAYS\n",
        "# ============================================================================\n",
        "#\n",
        "# - GA mimics natural evolution to find optimal hyperparameters\n",
        "# - Population evolves over generations through selection and reproduction\n",
        "# - Fitness function guides evolution toward better solutions\n",
        "# - Works well for hyperparameter optimization\n",
        "# - Simple to implement, effective for many problems\n",
        "#\n",
        "# ============================================================================\n",
        "# END OF EXPLANATION\n",
        "# ============================================================================"
      ]
    }
  ]
}